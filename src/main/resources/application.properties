spring.application.name=dfs-service
server.port=8082
#spring.dubbo.application.id=demo-dubbo-provider
#spring.dubbo.application.name=demo-dubbo-provider
#spring.dubbo.registry.address=zookeeper://192.168.26.139:2181
#spring.dubbo.server=true
#spring.dubbo.protocol.name=dubbo
#spring.dubbo.protocol.port=20880
spring.redis.host=10.0.0.5
# Redis服务器连接端口
spring.redis.port=6379
logging.config= classpath:log4j-spring-kafka.xml
hbase.zookeeper.quorum: 192.168.37.132
hbase.zookeeper.property.clientPort: 2181
zookeeper.znode.parent: /hbase
spring.data.elasticsearch.repositories.enabled=true
spring.data.elasticsearch.cluster-name=my-application
spring.data.elasticsearch.cluster-nodes=192.168.37.130:9300


#============== kafka ===================
# 指定kafka 代理地址，可以多个
spring.kafka.bootstrap-servers=192.168.37.131:9092
#spring.kafka.bootstrap-servers=192.168.230.145:9092

#=============== provider  =======================

spring.kafka.producer.retries=0
# 每次批量发送消息的数量
spring.kafka.producer.batch-size=16384
spring.kafka.producer.buffer-memory=33554432

# 指定消息key和消息体的编解码方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

#=============== consumer  =======================
# 指定默认消费者group id
spring.kafka.consumer.group-id=test-consumer-group

spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.auto-commit-interval=100

# 指定消息key和消息体的编解码方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer